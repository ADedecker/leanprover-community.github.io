---
layout: archive
title: Lean Prover Zulip Chat Archive
permalink: archive/219941MachineLearningforTheoremProving/34292HOList.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/index.html">Machine Learning for Theorem Proving</a>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html">HOList</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com">

{% raw %}
<a name="185555422"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185555422" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185555422">Jason Rute (Jan 14 2020 at 01:01)</a>:</h4>
<p><a href="https://sites.google.com/view/holist/home" target="_blank" title="https://sites.google.com/view/holist/home">DeepHOL/HOList</a> is Google Research neural-based automatic theorem prover for HOL Light.  A number of us have had deep discussions about it, how it works, and some of its design decisions.  Here are some highlights:</p>
<ul>
<li><span class="user-mention" data-user-id="213234">@Aaron Hadley</span>  and his team at UCF have made a great notebook demonstrating the "front end" Python API how to extend HOList to use other machine learning models <a href="https://github.com/aahadley/deepmath-jupyter/blob/master/HOLJup.ipynb" target="_blank" title="https://github.com/aahadley/deepmath-jupyter/blob/master/HOLJup.ipynb">here</a> and they also added a <a href="https://github.com/aahadley/deepmath-jupyter/blob/master/TutorialPaper.pdf" target="_blank" title="https://github.com/aahadley/deepmath-jupyter/blob/master/TutorialPaper.pdf">tutorial</a>.</li>
<li>If you are more interested in how DeepHOL (the neural prover) communicates with HOList (the modified from of HOL Light), here is a <a href="https://github.com/jasonrute/holist-communication-example" target="_blank" title="https://github.com/jasonrute/holist-communication-example">project of mine</a> which fleshes out the backend API.  In particular, <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">this notebook</a> walks you through the gRPC API.</li>
<li>It should be noted that a lot of the backend API is not used in the front end API.  For example, currently DeepHOL can't supply term parameters to tactics.  But it can choose tactics and choose theorem parameters (premise selection).</li>
<li>If anyone is interesting in hooking up Lean (or any other ITP) to DeepHOL, <a href="https://gist.github.com/jasonrute/00109af2bdc0974d2e8e79faf26ba556" target="_blank" title="https://gist.github.com/jasonrute/00109af2bdc0974d2e8e79faf26ba556">here</a> is a very preliminary best guess at what it would take to do it after talking with <span class="user-mention" data-user-id="217806">@Markus Rabe</span> at Google.</li>
</ul>

<a name="185555480"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185555480" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185555480">Jason Rute (Jan 14 2020 at 01:02)</a>:</h4>
<p>I know there are still a lot of questions about HOList (like why it uses s-expressions).  Feel free to discuss here.</p>

<a name="185575109"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185575109" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185575109">Stanislas Polu (Jan 14 2020 at 08:49)</a>:</h4>
<p>On the question of S-expression, I think that we went to the bottom of it through various private discussions. Pretty-printed HOL-light expressions which are appealing because they are close to what a human formalizing a proof would use are unfortunately ambiguous. The parser supports type annotation for human to disambiguate term types when coding in HOL Light, but unfortunately the pretty-printer is destructive such that <code>pretty_print o parse</code> is not the identity.</p>
<p>S-expressions are unambiguous as they are a natural way to marshal the in-memory representation of HOL Light terms (with every variable/constant being explicitly typed).</p>
<p>Ideally for some ML application, having compact representations is useful. Theoretically we could record the top-level semi-typed parsable theorem and term expressions and have them appear in proof logs as tactics arguments but that's probably not practical because hol-light starts by turning these expressions into in-memory representations, destroying the disambiguated human-provided terms.</p>
<p>Hope this context is useful!</p>

<a name="185593684"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185593684" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185593684">Jason Rute (Jan 14 2020 at 13:07)</a>:</h4>
<p>I think to take a step back, we have to acknowledge that s-expressions are used in 2.5 different ways in HOList.</p>
<ul>
<li>They are used as a serialization method to send HOL Light terms back and forth between HOList and DeepHOL (again, see my <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">"backend" walkthrough of HOList/DeepHOL</a>.)  This is sort of natural since the terms are algebraic data structures and s-expressions are natural for capturing such algebraic data structures.  This would generalize to any formal logic I can think of, making it sort of language neutral (before training).  However, I can also imagine one could use other serialization methods.  One could have used JSON or gRPC (which naturally translates to JSON) as the serialization method as well.  <span class="user-mention" data-user-id="246156">@Brando Miranda</span> has asked about JSON and said that Emilio at <a href="https://github.com/ejgallego/coq-serapi" target="_blank" title="https://github.com/ejgallego/coq-serapi">Serapi/Coq</a> was thinking about switching from s-expressions to JSON.  In some sense I don't think it matters much here as long as one uses a lossless encoding which is easy to parse.  (And in this case, these s-expressions are extremely easy to parse into whatever form one wants.)</li>
<li>They are also used as the text entered into the neural network model.  If one is using a pure sequence input model like an RNN or wavenet, then I think the idea is that you would plug the s-expression in as is (except one-hot encoding every token first?).  Or if one was using a tree or graph NN, then one naturally parses the s-expression into that tree or graph.  <span class="user-mention" data-user-id="249373">@Stanislas Polu</span> has lamented that the current s-expressions are probably too long for an RNN and has suggested shorter encodings.  Again, I think one has full freedom to play around with other representations.  I can think of many.  On the most compact side is to use the compact representation from the HOLStep data set.  It throws away types.  It uses polish notation.  And it uses skolemization and DeBruin indices for quantifiers and variables.  This however might be too compact.  HOList has found (from taking with Markus) that variable names matter a lot.  Another compact-ish approach would be to simulate the HOL Light pretty printer, but maybe add a few extra things.  It wouldn't be hard to get the parentheses the same as HOL Light.  As for types, the HOL Light pretty printer throws them away, but I think one might want to keep them for quantifiers and lambdas only.  Now, intermediate goals might not have any quantifiers, but one could borrow notation from say Lean and write something like this for an intermediate goal <code>(n: nat), (m: nat) |- = (num_add m n) (num_add n m)</code>.  It is hard to know what would work best without experimentation.  I've suggested that rather than trying this all out on HOList, it might be better to experiment first with some of the different string representations with different neural network models on HOLStep first since it is an easier to train dataset.  We would be looking for something which is quick to run but also does well on the task.  Since it is so up in the air what a good string input is, I think it wouldn't make sense to encode it into the HOList/DeepMath interface.  Instead, s-expressions work nice as a loss-less encoding which could be tweaked into something else when needed.</li>
<li>Last, one is also using these s-expressions as some sort of semi-human-readable term representation.  This is needed for debugging and understanding the outputs.  Again, the programmer is free to clean up the formula a bit for debugging, but most of the current HOList printouts use these s-expressions.</li>
</ul>
<p>So in summary, s-expressions try to be everything to everyone.  While in practice they might fail at that, they are pretty easy to parse and turn into something else.  The only exception is that the HOL Light pretty printed expressions are a bit complicated to 100% reproduce, but one can come close.  If it is important to have the exact pretty printed expressions, one could build that as another server call into the gRPC interface.  Get me the pretty printed version of this s-expression.</p>

<a name="185607167"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185607167" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185607167">Markus Rabe (Jan 14 2020 at 15:36)</a>:</h4>
<p>The response to any apply tactic request should already include the pretty printed version of the terms (as well as the s-expression, of course). Also all the theorem in the theorem database should have a pretty printed field in their proto.</p>

<a name="185624371"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185624371" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185624371">Christian Szegedy (Jan 14 2020 at 18:29)</a>:</h4>
<p>Our first models were convolutional networks that take the  tokenized s-expression (with types) as input. We have removed the parenthesis as well, as it is redundant, but makes parsing of the expressions a bit easier (esp. for humans). </p>
<p>We have tried to train sequence models on the pretty printed output as well, but it yielded inferior results to the models taking s-expressions as input.</p>
<p>Our graph-neural networks uses subexpression-sharing (still containing) which makes the input significantly shorter</p>
<p>Using JSON would have had the disadvantage that we would have needed a JSON parser in our Google internal version of HOL Light, which would have required importing extra packages.</p>

<a name="185655886"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185655886" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185655886">Jason Rute (Jan 15 2020 at 00:17)</a>:</h4>
<blockquote>
<p>The response to any apply tactic request should already include the pretty printed version of the terms </p>
</blockquote>
<p>I didn’t see this behavior in <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">my notebook</a>.  All the apply tactic calls only return the full s-expressions.  For example see cell 10.</p>

<a name="185746134"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185746134" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185746134">Patrick Massot (Jan 15 2020 at 21:28)</a>:</h4>
<p><span class="user-mention" data-user-id="110026">@Simon Hudon</span> are you following this thread in order to see how the Lean4 editor integration could also be a machine learning rig integration? Or is it something completely different?</p>

<a name="185746790"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185746790" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185746790">Jesse Michael Han (Jan 15 2020 at 21:35)</a>:</h4>
<p>such integration would be more structured than the current language server protocol, which does not serialize the environment, nor fully elaborated terms (and only does so as unstructured strings via JSON)</p>

<a name="185746915"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185746915" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185746915">Simon Hudon (Jan 15 2020 at 21:36)</a>:</h4>
<p>The next language server will serialize the syntax tree and the type information</p>

<a name="185747146"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747146" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747146">Simon Hudon (Jan 15 2020 at 21:38)</a>:</h4>
<p><span class="user-mention" data-user-id="110031">@Patrick Massot</span>, does that answer your question? I'm not sure I understood what you were looking for</p>

<a name="185747174"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747174" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747174">Simon Cruanes (Jan 15 2020 at 21:39)</a>:</h4>
<p>So it'll still be bespoke and not LSP based?</p>

<a name="185747579"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747579" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747579">Patrick Massot (Jan 15 2020 at 21:43)</a>:</h4>
<blockquote>
<p>So it'll still be bespoke and not LSP based?</p>
</blockquote>
<p>We can add as many extension to LSP as we want.</p>

<a name="185747586"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747586" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747586">Simon Hudon (Jan 15 2020 at 21:43)</a>:</h4>
<p>We're basing it on LSP but we're going to get beyond the LSP basic features for the more advance uses</p>

<a name="185747611"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747611" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747611">Patrick Massot (Jan 15 2020 at 21:43)</a>:</h4>
<blockquote>
<p>Patrick Massot, does that answer your question? I'm not sure I understood what you were looking for</p>
</blockquote>
<p>I have no idea. I only hope people who followed this thread will know.</p>

<a name="185747612"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747612" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747612">Mario Carneiro (Jan 15 2020 at 21:43)</a>:</h4>
<p>I'm hoping you document those extensions</p>

<a name="185747736"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747736" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747736">Simon Cruanes (Jan 15 2020 at 21:45)</a>:</h4>
<blockquote>
<p>We can add as many extension to LSP as we want.</p>
</blockquote>
<p>yes, but LSP remains based on buffers and JSON, I'm not sure I see how you can carry ASTs on it efficiently?</p>

<a name="185747750"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747750" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747750">Mario Carneiro (Jan 15 2020 at 21:45)</a>:</h4>
<p>you can json anything</p>

<a name="185747804"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747804" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747804">Mario Carneiro (Jan 15 2020 at 21:46)</a>:</h4>
<p>I guess the efficiency isn't so great, but as long as it's only sent when needed it shouldn't be so bad</p>

<a name="185747855"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747855" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747855">Simon Cruanes (Jan 15 2020 at 21:46)</a>:</h4>
<p>sometimes I wish LSP had been built on msgpack-rpc or something like that</p>

<a name="185748765"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185748765" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185748765">Mario Carneiro (Jan 15 2020 at 21:58)</a>:</h4>
<p>huh, msgpack is pretty cool</p>

<a name="185749163"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185749163" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185749163">Simon Cruanes (Jan 15 2020 at 22:03)</a>:</h4>
<p>especially when you want to embed big chunks of code into it… no escaping needed</p>

<a name="186201897"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186201897" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186201897">Stanislas Polu (Jan 21 2020 at 16:46)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> and others friends knowledgeable about Holist. I've been able to spin up a holist instance using the <code>gcr.io/deepmath/hol-light</code> image. One thing that I expected from reading the code and introspecting the proof logs was that all theorems fingerprints appearing in the proof logs would be directly usable with that image but it looks like that's not the case. How does one is supposed to interact with the prover for a goal part of the test set? Do they have to replay and register all theorems first?</p>

<a name="186202542"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186202542" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186202542">Stanislas Polu (Jan 21 2020 at 16:53)</a>:</h4>
<p>Example code failing:</p>
<div class="codehilite"><pre><span></span>for_all_x_exists_y_x_equals_y = Theorem(
    name=&quot;FORALL_X_EXISTS_Y_SUCH_THAT_X_EQUALS_Y&quot;,
    conclusion=&quot;(a (c (fun (fun A (bool)) (bool)) !) (l (v A x) (a (c (fun (fun A (bool)) (bool)) ?) (l (v A y) (a (a (c (fun A (fun A (bool))) =) (v A x)) (v A y))))))&quot;,
    training_split=Theorem.Split.TESTING,
    tag=Theorem.Tag.THEOREM,
)

if __name__ == &#39;__main__&#39;:
    with grpc.insecure_channel(&#39;10.72.7.138:2000&#39;) as channel:
        stub = ProofAssistantServiceStub(channel)

        request3 = ApplyTacticRequest(goal=for_all_x_exists_y_x_equals_y, tactic=&quot;SIMP_TAC [ THM 220805353555668225 ]&quot;)
        print(&quot;Request:&quot;)
        print(request3)

        response3 = stub.ApplyTactic(request3)
        print(&quot;Response:&quot;)
        print(response3)
</pre></div>


<p>Where <code>220805353555668225</code> is the fingerprint of a theorem argument taken from the training set (appears in <code>human/train/prooflogs-00037-of-00600.pbtxt</code>)</p>
<p>This gives:</p>
<div class="codehilite"><pre><span></span>Request:
goal {
  conclusion: &quot;(a (c (fun (fun A (bool)) (bool)) !) (l (v A x) (a (c (fun (fun A (bool)) (bool)) ?) (l (v A y) (a (a (c (fun A (fun A (bool))) =) (v A x)) (v A y))))))&quot;
  tag: THEOREM
  name: &quot;FORALL_X_EXISTS_Y_SUCH_THAT_X_EQUALS_Y&quot;
  training_split: TESTING
}
tactic: &quot;SIMP_TAC [ THM 220805353555668225 ]&quot;

Response:
error: &quot;Failure(\&quot;No theorem exists with index 220805353555668225\&quot;)&quot;
</pre></div>

<a name="186202862"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186202862" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186202862">Stanislas Polu (Jan 21 2020 at 16:56)</a>:</h4>
<p>Or in other words how can I easily replay a proof log ?</p>

<a name="186203965"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186203965" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186203965">Stanislas Polu (Jan 21 2020 at 17:06)</a>:</h4>
<p>Ah I now realize that some theorems in <code>theorem_database_v1.1.textpb</code> are registered and usable.  I think only definitions are registered, but other theorems are not. </p>
<p>The question therefore remains?</p>

<a name="186210355"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186210355" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186210355">Jason Rute (Jan 21 2020 at 18:10)</a>:</h4>
<p>I was under the impression, possibly wrong, that one needs to replay (VerifyProof) and register (RegisterTheorem) all the theorems.  Of course this is assuming you are working in the “low level” gRPC API.  If you are working in the “high level” Python API then I assume the Python code does that stuff for you, but I haven’t explored that as much yet.</p>

<a name="186211833"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186211833" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186211833">Stanislas Polu (Jan 21 2020 at 18:27)</a>:</h4>
<p>Maybe <span class="user-mention" data-user-id="217806">@Markus Rabe</span> or <span class="user-mention" data-user-id="239426">@Christian Szegedy</span> can shed some light on this? <span aria-label="grimacing" class="emoji emoji-1f62c" role="img" title="grimacing">:grimacing:</span></p>

<a name="186218006"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186218006" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186218006">Christian Szegedy (Jan 21 2020 at 19:31)</a>:</h4>
<blockquote>
<blockquote>
<p>The response to any apply tactic request should already include the pretty printed version of the terms </p>
</blockquote>
<p>I didn’t see this behavior in <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">my notebook</a>.  All the apply tactic calls only return the full s-expressions.  For example see cell 10.</p>
</blockquote>
<p>It looks like (unfortunately) that this is only in our Google-internal version. We could do another round of exporting, especially that we have some code for an ICLR paper that should be open-sourced as well.</p>

<a name="186218426"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186218426" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186218426">Christian Szegedy (Jan 21 2020 at 19:35)</a>:</h4>
<blockquote>
<p>I was under the impression, possibly wrong, that one needs to replay (VerifyProof) and register (RegisterTheorem) all the theorems.  Of course this is assuming you are working in the “low level” gRPC API.  If you are working in the “high level” Python API then I assume the Python code does that stuff for you, but I haven’t explored that as much yet.</p>
</blockquote>
<p>The current verifier verifies theorems in their original context. So currently. you need to replay the whole theorem library in order to verify any number of theorems:<br>
- You can verify only theorems that came from the HOL-Light library (complex),<br>
- You can verify any number of theorems (you don't need to verify all of them)<br>
- All the theorems in the library will be run through the kernel for verification.<br>
- Those theorems that had an external proof (to be verified) will use their external proof at exactly that position where the theorem was proved originally.</p>

<a name="186220118"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186220118" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186220118">Christian Szegedy (Jan 21 2020 at 19:52)</a>:</h4>
<blockquote>
<p>Ah I now realize that some theorems in <code>theorem_database_v1.1.textpb</code> are registered and usable.  I think only definitions are registered, but other theorems are not. </p>
<p>The question therefore remains?</p>
</blockquote>
<p>The human prooflogs contain proof-steps that rely on theorems created "on the fly" by forward reasoning steps (so called conversions). These theorems don't show up in the theorem database. Also proofs relying on them can't be replayed as conversions can't be replayed either.</p>
<p>On the other hand the exported tensorflow examples contain the actual s-expression of those parameters, so if somebody uses those examples, the corresponding theorem can be used for training the parameter-selection models, even if those tactic-parameters don't show up in the proof-logs.</p>
<p>Around 60% of the human proofs can be replayed, as a large number of them uses theorems deduced by forward reasoning steps, other theorems use ad-hoc substitution of terms that we did not log either.</p>

<a name="186252165"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186252165" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186252165">Markus Rabe (Jan 22 2020 at 03:20)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> <span class="user-mention" data-user-id="115715">@Jason Rute</span><br>
The example above failed because the theorem with the fingerprint (or "index") 220805353555668225 is unknown to HOL Light when it is started up. Only the "core" Theorems are loaded at that point (which includes some basic definitions and theorems). Before you use any other theorem you need to register that theorem with the RegisterTheoremRequest.</p>
<p>As Christian said, don't expect all human-written proofs to go through, as some tactics are not supported and not all theorems that humans used in the proofs are in our theorem database.</p>
<p>As a final note: VerifyProof was only used for a deprecated version of our proof checker. Currently it is not used for anything and should be ignored.</p>

<a name="186268156"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186268156" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186268156">Stanislas Polu (Jan 22 2020 at 09:18)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> Thanks! Let me experiment with that. Ack re the obvious non-possibility to input any human proof. That being said, is it true that we can proof check all the proofs in the proof logs?</p>

<a name="186268720"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186268720" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186268720">Stanislas Polu (Jan 22 2020 at 09:26)</a>:</h4>
<p>Ah from reading <span class="user-mention" data-user-id="239426">@Christian Szegedy</span> post above I realize that property (replayability of the proof logs) does not hold true. If only 60% of the human proofs can be replayed, then 60% is somewhat of an upper bound on the performance of any supervised prover, right? (not sure it's mentioned in the papers?)</p>

<a name="186269417"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186269417" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186269417">Stanislas Polu (Jan 22 2020 at 09:35)</a>:</h4>
<blockquote>
<p>On the other hand the exported tensorflow examples contain the actual s-expression of those parameters, so if somebody uses those examples, the corresponding theorem can be used for training the parameter-selection models, even if those tactic-parameters don't show up in the proof-logs.</p>
</blockquote>
<p>I was under the impression that the information contained in the proof logs (pbtxt) was equivalent to the information contained in the tf examples (for the positive arguments) ? Is it not true? Is there a source of truth for the specification of the content of these files?</p>

<a name="186269695"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186269695" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186269695">Stanislas Polu (Jan 22 2020 at 09:39)</a>:</h4>
<p>Finally <span class="user-mention" data-user-id="217806">@Markus Rabe</span> is your latest comment on VerifyProof true of the publicly available version? (Thanks thanks!)</p>

<a name="186272422"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186272422" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186272422">Jason Rute (Jan 22 2020 at 10:14)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> I’m under the impression from my experiments with the public HOList Docker image that one has to first verify a theorem before one can register it (and it has to be the most recently verified theorem).  I assume this has gone away in the internal versions.</p>

<a name="186272506"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186272506" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186272506">Jason Rute (Jan 22 2020 at 10:15)</a>:</h4>
<p>Also, I assume the way that RegisterTheorem now works is to add the theorem as an axiom using the CHEAT tactic?</p>

<a name="186278286"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186278286" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186278286">Stanislas Polu (Jan 22 2020 at 11:39)</a>:</h4>
<p>Form the code in [0], it looks like anything received from RegisterTheorem is indeed assumed:</p>
<div class="codehilite"><pre><span></span>Theorem_fingerprint.index_thm index (Drule.mk_thm (to_term_list gs));
</pre></div>


<p>As Drule.mk_thm is a wrapper around the ASSUME tactic I believe.</p>
<p>But unclear if [0] is what is deployed in the <code>gcr.io/deepmath/hol-light</code> image?</p>
<p>[0] <a href="https://github.com/brain-research/hol-light/blob/master/sandboxee.ml#L141-L144" target="_blank" title="https://github.com/brain-research/hol-light/blob/master/sandboxee.ml#L141-L144">https://github.com/brain-research/hol-light/blob/master/sandboxee.ml#L141-L144</a></p>

<a name="186305426"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186305426" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186305426">Stanislas Polu (Jan 22 2020 at 16:46)</a>:</h4>
<p>I confirm that you can register any theorem (Only caveat is that it seems that the fingerprint does not get returned if not passed).</p>

<a name="186305605"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186305605" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186305605">Stanislas Polu (Jan 22 2020 at 16:48)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> can you expand on the limitation related to conversions? Replaying the prooflogs would just fail there? From skimming through the <a href="http://parse_tactic.ml" target="_blank" title="http://parse_tactic.ml">parse_tactic.ml</a> code it looks like there is some support for conversions? What are the current limitations?</p>

<a name="186329092"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186329092" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186329092">Christian Szegedy (Jan 22 2020 at 20:45)</a>:</h4>
<blockquote>
<p>If only 60% of the human proofs can be replayed, then 60% is somewhat of an upper bound on the performance of any supervised prover, right? (not sure it's mentioned in the papers?)</p>
</blockquote>
<p>This is not necessarily true. Since we use the network to guide a search, if the search explores enough branches it can discover proofs that are alternative to the human proofs.</p>

<a name="186329489"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186329489" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186329489">Christian Szegedy (Jan 22 2020 at 20:50)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="239426">Christian Szegedy</span> can you expand on the limitation related to conversions? Replaying the prooflogs would just fail there? From skimming through the <a href="http://parse_tactic.ml" target="_blank" title="http://parse_tactic.ml">parse_tactic.ml</a> code it looks like there is some support for conversions? What are the current limitations?</p>
</blockquote>
<p>We log some of the conversions, but the ApplyTactic function call can't make use of them.</p>
<p>We have a new internal extension to the API that allows the application of "rules" (forward reasoning steps), we have run some preliminary expriments using them, but we don't have a proper integration, especially proof replay and verification are not implemented for them. We plan to open source our extensions to the interface as soon as there is enough interest in the community to use it.</p>

<a name="186330963"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186330963" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186330963">Christian Szegedy (Jan 22 2020 at 21:06)</a>:</h4>
<p>BTW, this is the code to properly initialize the environment with all of the (complex) proofs:</p>
<p><a href="https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359" target="_blank" title="https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359">https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359</a></p>

<a name="186332996"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186332996" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186332996">Markus Rabe (Jan 22 2020 at 21:30)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> You're right. The publicly available version of our modified HOL Light still includes the old proof checker. It should still work. <br>
What I meant is that we have a new proof checker that bypasses the API and instead compiles proof logs to OCaml code. Thereby we don't have to trust our Python code and the API. The new proof checker is described at <a href="http://deephol.org" target="_blank" title="http://deephol.org">deephol.org</a>.</p>

<a name="186333304"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186333304" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186333304">Markus Rabe (Jan 22 2020 at 21:33)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> <span class="user-mention" data-user-id="249373">@Stanislas Polu</span> Indeed, you can even register terms that are not true. So it is your responsibility to stay sound in the stateless API. (Hence our stand-alone proof checker.)</p>

<a name="186366816"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186366816" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186366816">Stanislas Polu (Jan 23 2020 at 08:18)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span>  Thanks for your additional comments</p>

<a name="186366828"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186366828" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186366828">Stanislas Polu (Jan 23 2020 at 08:18)</a>:</h4>
<blockquote>
<p>BTW, this is the code to properly initialize the environment with all of the (complex) proofs:<br>
<a href="https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359" target="_blank" title="https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359">https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359</a></p>
</blockquote>
<p>I had stumbled on this and was plan to use exactly that <span aria-label="+1" class="emoji emoji-1f44d" role="img" title="+1">:+1:</span></p>
<blockquote>
<p>We have a new internal extension to the API that allows the application of "rules" (forward reasoning steps), we have run some preliminary expriments using them, but we don't have a proper integration, especially proof replay and verification are not implemented for them. We plan to open source our extensions to the interface as soon as there is enough interest in the community to use it.</p>
</blockquote>
<p>There is interest to use it :)</p>

<a name="186366915"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186366915" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186366915">Stanislas Polu (Jan 23 2020 at 08:20)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> thanks!</p>

<a name="186367435"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186367435" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186367435">Stanislas Polu (Jan 23 2020 at 08:30)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> Let me rephrase a bit what you stated. Even without support for forward reasoning with conversions one could imagine that a system that takes the results of the conversion (input to later tactics) as part of its training set, it could potentially replay some theorems successfully skipping entirely the conv step. Do you guys include these theorems to your database when training?</p>

<a name="186409482"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186409482" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186409482">Christian Szegedy (Jan 23 2020 at 16:56)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> If you mean by "replay" proving the theorem in a different way, then yes. It happens a lot. Actually, machine generated proofs tend to be quite different from human proofs, even if premise selection was trained by imitation only. Also logging (and training on) "theorems" (or true statements) produced by the conversions is still useful for training the models that decides which tactic parameters are the most useful, even if the prover process cannot do conversions. That's what we do.</p>

<a name="186421586"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186421586" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186421586">Stanislas Polu (Jan 23 2020 at 18:52)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> thanks!</p>

<a name="186476176"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186476176" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186476176">Stanislas Polu (Jan 24 2020 at 09:43)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> I'm a bit surprised by the following:</p>
<div class="codehilite"><pre><span></span>root@dev-1-0:~# du -h ~/deephol-data/deepmath/deephol/proofs/human/test
3.3G    /root/deephol-data/deepmath/deephol/proofs/human/test
root@dev-1-0:~# du -h ~/deephol-data/deepmath/deephol/proofs/human/valid
2.4G    /root/deephol-data/deepmath/deephol/proofs/human/valid
root@dev-1-0:~# du -h ~/deephol-data/deepmath/deephol/proofs/human/train
9.2G    /root/deephol-data/deepmath/deephol/proofs/human/train
</pre></div>


<p>vs</p>
<div class="codehilite"><pre><span></span>root@dev-1-0:~# grep &quot;TEST&quot; ~/deephol-data/deepmath/deephol/theorem_database_v1.1.textpb | wc -l
14141
root@dev-1-0:~# grep &quot;VALIDATION&quot; ~/deephol-data/deepmath/deephol/theorem_database_v1.1.textpb | wc -l
3668
root@dev-1-0:~# grep &quot;TRAINING&quot; ~/deephol-data/deepmath/deephol/theorem_database_v1.1.textpb | wc -l
11655
</pre></div>


<p>Which gives a bytes/theorem (approximation) of:</p>
<div class="codehilite"><pre><span></span>TEST: ~233k
VALIDATION: ~654k
TRAIN: ~789k
</pre></div>


<p>Which indicates that the size of the proofs in the test set are noticeably smaller vs train/validation? Is that intentional? (or maybe a discrepancy in tf records for the test set?)</p>

<a name="186487969"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186487969" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186487969">Stanislas Polu (Jan 24 2020 at 12:46)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> sorry another quick question. It looks like <code>LABEL_TAC</code> is not accepted by the proof assistant. Any reason why they appear in the proof logs?</p>

<a name="186491122"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186491122" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186491122">Stanislas Polu (Jan 24 2020 at 13:25)</a>:</h4>
<p>FInally, while attempting to replay the proof logs with the following procedure: for all tactics taking a theorem argument, call RegisterTheorem on each argument and then for all tactics, call ApplyTactic.</p>
<p>I often, despite a successful call to RegisterTheorem (the fingerprint I use (the one from the proof logs) is returned to me with no error), I get an eventual error when applying the tactic with message "No theorem exists with index XXX". From reading the ML code, I have a hard time seeing how the fingerprint can be returned successfully at RegisterTheorem and then not being hitting that message meaning that the index does not has that fingerprint.</p>
<p>Example logs:</p>
<div class="codehilite"><pre><span></span>Replaying /Users/spolu/deephol-data/deepmath/deephol/proofs/human/test/prooflogs-00218-of-00537.jsonl
&gt; ApplyTactic X_GEN_TAC `(v (fun (cart (real) N) (bool)) s)`
&lt; ApplyTactic 1 goals
&gt; ApplyTactic X_GEN_TAC `(v (fun (cart (real) N) (bool)) t)`
&lt; ApplyTactic 1 goals
&gt; ApplyTactic DISCH_TAC
&lt; ApplyTactic 1 goals
&gt; ApplyTactic RAW_POP_TAC 0
&lt; ApplyTactic 1 goals
&gt; RegisterTheorem 3261843337692443473
&lt; RegisterTheorem 3261843337692443473
&gt; ApplyTactic REWRITE_TAC [ THM 3261843337692443473 ]
&lt; ApplyTactic 1 goals
&gt; RegisterTheorem 3276577123099513888
&lt; RegisterTheorem 3276577123099513888
&gt; ApplyTactic MP_TAC THM 3276577123099513888
!!! Failure(&quot;No theorem exists with index 3276577123099513888&quot;)
&gt; RegisterTheorem 3550116108290505704
&lt; RegisterTheorem 3550116108290505704
&gt; RegisterTheorem 1457252911920550478
&lt; RegisterTheorem 1457252911920550478
&gt; RegisterTheorem 4032148915606337071
&lt; RegisterTheorem 4032148915606337071
&gt; RegisterTheorem 1358160238249633387
&lt; RegisterTheorem 1358160238249633387
&gt; RegisterTheorem 34540287283234494
&lt; RegisterTheorem 34540287283234494
&gt; RegisterTheorem 3806712188414811372
&lt; RegisterTheorem 3806712188414811372
&gt; ApplyTactic SIMP_TAC [ THM 3550116108290505704 ; THM 1457252911920550478 ; THM 4032148915606337071 ; THM 1358160238249633387 ; THM 34540287283234494 ; THM 3806712188414811372 ]
!!! Failure(&quot;No theorem exists with index 34540287283234494&quot;)
&gt; ApplyTactic DISCH_TAC
&lt; ApplyTactic 1 goals
&gt; ApplyTactic RAW_POP_TAC 0
&lt; ApplyTactic 1 goals
&gt; RegisterTheorem 4441231563045595206
&lt; RegisterTheorem 4441231563045595206
&gt; ApplyTactic MP_TAC THM 4441231563045595206
!!! Failure(&quot;No theorem exists with index 4441231563045595206&quot;)
&gt; ApplyTactic ANTS_TAC
&lt; ApplyTactic 2 goals
&gt; RegisterTheorem 647530560333096154
&lt; RegisterTheorem 647530560333096154
&gt; ApplyTactic REWRITE_TAC [ THM 647530560333096154 ]
&lt; ApplyTactic 1 goals
</pre></div>


<p>As you can see this happens quite often.<br>
cc <span class="user-mention" data-user-id="217806">@Markus Rabe</span> <span class="user-mention" data-user-id="239426">@Christian Szegedy</span></p>

<a name="186491176"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186491176" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186491176">Stanislas Polu (Jan 24 2020 at 13:26)</a>:</h4>
<p>(sorry for all the questions, hope it'll be useful to the community)</p>

<a name="186495853"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186495853" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186495853">Stanislas Polu (Jan 24 2020 at 14:22)</a>:</h4>
<p>I believe I found what is going on from inspecting the logs of the container. It seems that the fingerprint mismatch. Unfortunately the "api" does not return the newly computed fingerprint but only the fingerprint passer as argument, but does use the new fingerprint for indexing. This is a bit unfortunate.</p>

<a name="186495865"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186495865" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186495865">Stanislas Polu (Jan 24 2020 at 14:22)</a>:</h4>
<p>(I'll explore as to why there are discrepancies in fingerprints)</p>

<a name="186498505"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186498505" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186498505">Stanislas Polu (Jan 24 2020 at 14:54)</a>:</h4>
<p>Problem solved on my end by fixing discrepancies in the S-Expr I was sending (escaped characters were not handled properly). Replaying logs seems to work properly now \o/ Hope this is all useful to others.</p>

<a name="186506019"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186506019" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186506019">Stanislas Polu (Jan 24 2020 at 16:13)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> in your walkthrough[0], the TRANS_TAC marshalling is a bit wrong. It takes a theorem then a term.<br>
[0] <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb</a></p>

<a name="186507286"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186507286" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186507286">Markus Rabe (Jan 24 2020 at 16:27)</a>:</h4>
<p>All good questions. Note that the theorem database also includes the flyspeck corpus, but I believe we have not published the proof logs for flyspeck. I believe the flyspeck theorems are all labeled as TESTING. Hence your divisor is off for testing. If you want to be even more precise you should also discount the definitions, as they do not have proofs.</p>
<p>But still interesting that the size of the training for TESTING is significantly larger than for VALIDATION. I wasn't aware of that.</p>

<a name="186507358"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186507358" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186507358">Markus Rabe (Jan 24 2020 at 16:28)</a>:</h4>
<p>LABEL_TAC and other unsupported tactics are in the proof logs as we log the proofs as the humans wrote them.</p>

<a name="186507925"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186507925" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186507925">Markus Rabe (Jan 24 2020 at 16:34)</a>:</h4>
<p>As for the failures of RegisterTheorem: Yes, the fingerprint is unfortunately not the one computed in HOL Light, but just the one that you indicated in the register theorem request. We're fixing this internally as well, so any future releases should not have the problem. Thanks for noticing and for all the work you've put in!</p>

<a name="186523943"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186523943" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186523943">Stanislas Polu (Jan 24 2020 at 19:15)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> thanks a lot for all your help. One quite orthogonal question, what is the rationale for the current API (somewhat constrained in term of tactics available) vs directly interacting with a live hol light goal stack (which would accept pretty much anything)?</p>

<a name="186597371"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186597371" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186597371">Markus Rabe (Jan 26 2020 at 01:38)</a>:</h4>
<p>Several reasons afaik: we need a stateless API, and we wanted to communicate via proto messages to abstract from the fact that we use HOL Light and to have flexibility in the deployment of the provers.</p>

<a name="186719316"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186719316" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186719316">Stanislas Polu (Jan 27 2020 at 19:58)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> the original Holist paper[0] states that final results should be shared using the test set (4.2) but it looks like the main result is produced on the validation set (Table 2) and there is no such result for the test set? I believe it is the same for the SoTa paper [1]. Am I missing something?<br>
[0] <a href="https://arxiv.org/pdf/1904.03241.pdf" target="_blank" title="https://arxiv.org/pdf/1904.03241.pdf">https://arxiv.org/pdf/1904.03241.pdf</a><br>
[1] <a href="https://arxiv.org/pdf/1905.10006.pdf" target="_blank" title="https://arxiv.org/pdf/1905.10006.pdf">https://arxiv.org/pdf/1905.10006.pdf</a></p>

<a name="186719383"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186719383" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186719383">Stanislas Polu (Jan 27 2020 at 19:59)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> Thanks. Arguably you could have created a new GoalStack for each request and have full support of the Tactics? Is there a reason why you didn't go for that?</p>

<a name="186719764"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186719764" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186719764">Stanislas Polu (Jan 27 2020 at 20:03)</a>:</h4>
<p>Finally, the last set of errors I'm getting when "replaying" the validation set are related to CONV tactics (which I believe are expected since I can see in the ML code that the CONV passed to CONV_TAC are not supported), example:</p>
<div class="codehilite"><pre><span></span>&gt; ApplyTactic CONV_TAC REAL_FIELD
!!! Failure(&quot;Parse failure at :9: expected conv but found REAL_FIELD&quot;)
--
&gt; ApplyTactic CONV_TAC COND_ELIM_CONV
!!! Failure(&quot;Parse failure at :9: expected conv but found COND_ELIM_CONV&quot;)
</pre></div>


<p>I also have a few errors that seem to be due to an erroneous tracing, example:</p>
<div class="codehilite"><pre><span></span>&gt; ApplyTactic X_CHOOSE_TAC `(v (cart (real) N) y)` THM 1452504403316335102
!!! Failure(&quot;X_CHOOSE_TAC: expected type :real^M but got :real^N&quot;)
</pre></div>


<p>Are you guys aware of those ^</p>
<p>Finally, the identify is sometime passed to the GEN_WRITE_TAC as <code>I</code> but it does not seem supported, is that expected?</p>
<div class="codehilite"><pre><span></span>&gt; ApplyTactic GEN_REWRITE_TAC I [ THM 2993471090521929300 ]
!!! Failure(&quot;Parse failure at :16: expected convfn but found I&quot;)
</pre></div>

<a name="186741900"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186741900" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186741900">Christian Szegedy (Jan 28 2020 at 00:37)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="239426">Christian Szegedy</span> the original Holist paper[0] states that final results should be shared using the test set (4.2) but it looks like the main result is produced on the validation set (Table 2) and there is no such result for the test set? I believe it is the same for the SoTa paper [1]. Am I missing something?</p>
</blockquote>
<p>Yes, I think it is sloppiness on our side. We have verified our results internally with the test set and the results were very close. Also, we got pretty decent results on the Flyspeck corpus which is a completely independent branch from the training set. This is also reported in the HOList paper.</p>
<p>We will rerun our model from the GNN paper with the test set and update the paper. I am quite confident that the results don't change significantly to the validation set as we did not do a lot of tuning on it.</p>

<a name="186742113"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186742113" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186742113">Christian Szegedy (Jan 28 2020 at 00:40)</a>:</h4>
<blockquote>
<p>Finally, the last set of errors I'm getting when "replaying" the validation set are related to CONV tactics (which I believe are expected since I can see in the ML code that the CONV passed to CONV_TAC are not supported), example:</p>
</blockquote>
<p>All those errors are expected. Currently the API supports only theorem parameters and only the selected set of 42 tactics we have enabled.</p>

<a name="186750599"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186750599" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186750599">Christian Szegedy (Jan 28 2020 at 03:40)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="239426">Christian Szegedy</span> the original Holist paper[0] states that final results should be shared using the test set (4.2) but it looks like the main result is produced on the validation set (Table 2) and there is no such result for the test set? I believe it is the same for the SoTa paper [1]. Am I missing something?<br>
[0] <a href="https://arxiv.org/pdf/1904.03241.pdf" target="_blank" title="https://arxiv.org/pdf/1904.03241.pdf">https://arxiv.org/pdf/1904.03241.pdf</a><br>
[1] <a href="https://arxiv.org/pdf/1905.10006.pdf" target="_blank" title="https://arxiv.org/pdf/1905.10006.pdf">https://arxiv.org/pdf/1905.10006.pdf</a></p>
</blockquote>
<p>Sarah has rerun the model from the GNN paper for the validation and training set and verified the validation set performance at 49.98% (we proved 1 theorem less with the current code , which is in noise range), the test set performance is 46.89% (1493 theorem proved out of 3184). We will update the paper accordingly. We don't think that the 2% gap is the result of overfitting, since during the test set construction, we needed to deduplicate some simple theorems that occurred in both the training, validation and test sets and ended up in the training and validation sets, depending on which sets they were contained in.</p>
<p>We are also waiting for the "deeper wavenet" result from the HOList paper and will update that paper as well.</p>
<p>Thanks a lot for constructive suggestion!</p>

<a name="186760332"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186760332" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186760332">Stanislas Polu (Jan 28 2020 at 08:01)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> thanks for the quick answer (and thanks to Sarah et al for re-running the model on the test set \o/)</p>

<a name="186777567"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186777567" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186777567">Stanislas Polu (Jan 28 2020 at 12:28)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> (sorry for the continuous stream of questions) using <code>theorem_database_v1.1.textpb</code> I get the following counts, filtering out <code>"flyspeck" in library_tag</code> and considering only <code>tag=THEOREM</code>:</p>
<div class="codehilite"><pre><span></span>    3618 test_benchmark
   11654 train_benchmark
    3666 validation_benchmark
</pre></div>


<p>Any idea where is the discrepancy with the number you report above (3184 theorems for the test set) coming from?</p>

<a name="186778038"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186778038" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186778038">Stanislas Polu (Jan 28 2020 at 12:35)</a>:</h4>
<blockquote>
<p>All those errors are expected. Currently the API supports only theorem parameters and only the selected set of 42 tactics we have enabled.</p>
</blockquote>
<p>Just wanted to note that the (hol-light fork) grpc API do support <code>term</code> parameters as well as a selection of <code>convfn</code> parameters, but not all of them</p>

<a name="186782109"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186782109" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186782109">Sarah Loos (Jan 28 2020 at 13:30)</a>:</h4>
<p>There are library tags that split core, complex, and flyspeck. The counts you give are for core+complex. However, we need to prove core before our 41 tactics are defined, so proving them again using those 41 tactics could allow circular proofs.  We train on complex + core, but we validate and test on complex alone. That leaves 3225 theorems in validation, and 3184 in test (fewer in test due to the deduplication Christian already mentioned.</p>

<a name="186802045"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186802045" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186802045">Stanislas Polu (Jan 28 2020 at 16:55)</a>:</h4>
<p>Thanks <span class="user-mention" data-user-id="239408">@Sarah Loos</span> that perfectly answers my question!</p>

<a name="187261298"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187261298" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187261298">Stanislas Polu (Feb 03 2020 at 13:26)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> <span class="user-mention" data-user-id="239426">@Christian Szegedy</span> could you shed some light on the nature of the theorems used as arguments of tactics in the proof logs but that are never proved in the proof logs and do not appear in the theorem database. A good number of such theorems appear to be simple REFL forms <code>t |- t</code> but that's not always true. A few interesting examples that are never proved and do not appear immediately trivial (there are thousands of those):</p>
<div class="codehilite"><pre><span></span>- 1922886628595100084 used in [&quot;3005304601846519849&quot;]
- 4128119696079773064 used in [&quot;1490865809968625449&quot;, &quot;203472435947866096&quot;, &quot;2108783368615713599&quot;, &quot;2832673211645131567&quot;, &quot;954493053183470525&quot;]
</pre></div>


<p>In particular, since they appear in proof logs as valid premises, do you consider valid the use of these theorems by a prover against your benchmark?</p>

<a name="187263434"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187263434" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187263434">Stanislas Polu (Feb 03 2020 at 13:53)</a>:</h4>
<p>(and if so) under which ordering constraints</p>

<a name="187274148"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187274148" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187274148">Stanislas Polu (Feb 03 2020 at 15:50)</a>:</h4>
<p>After further exploration I can see 86747 such unproven but used theorems across train/test/valid of which 56726 are trivial "REFLs" (which are therefore trivially provable).</p>

<a name="187296782"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187296782" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187296782">Sarah Loos (Feb 03 2020 at 19:48)</a>:</h4>
<p>There is a difference between the human proofs that we have logged and the synthetic proofs.  </p>
<p>From your description, I believe you're looking at the human proofs.  We only recorded backward tactics (loosely speaking, steps of type tactic in HOL Light, which convert a goal to a new goalstate).  We did not implement logging for human theorems that are generated via forward steps (e.g. from rules that convert thm-&gt;thm in HOL Light, like SPECL).  Many human proofs are a combination of forward and backward proof steps.  In training, we keep these forward generated theorems as arguments, since they still have semantic meaning that is useful for training, but at present we would not be able to generate these exact proofs, since the forward-derived theorems are not available in our theorem database and we have not yet implemented forward proving steps.  This doesn't mean that the theorem can't be proved via DeepHOL, just that it may need to take more backward steps to close the goal. </p>
<p>Another place that these theorems can come from is the assumption list in the goal.  I believe around 45% of the theorem arguments in the human training steps come directly from the assumption list in the current goal.  These can come from either being explicitly passed as tactic arguments, or added in bulk via an ASM_* tactic.</p>
<p>Regarding the synthetic proofs, these arguments should all come from the theorem database as you expected.</p>

<a name="187298282"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187298282" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187298282">Stanislas Polu (Feb 03 2020 at 20:05)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> Thanks! Yes, talking about the human proofs.</p>
<p>So it would be rather unfair to add these theorems to the theorem database of the prover (they should rather be re-demonstrated (in some backward way) at proof time if needed) since they do carry the forward reasoning steps that produced them (however simple they are).</p>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> mentioned that you had an internal version that would extend support for forward reasoning / conversions, are the proof logs different in that next version how would that change the overall picture here?</p>

<a name="187299056"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187299056" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187299056">Stanislas Polu (Feb 03 2020 at 20:15)</a>:</h4>
<p>(from re-reading earlier posts, I presume it would allow to technically generate these theorems through forward reasoning steps, but your current system does not cover creating the associated proof logs. Aka you added a forward reasoning API to register new theorems through conversions, but the proof logs remain the same?)</p>

<a name="187299723"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187299723" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187299723">Christian Szegedy (Feb 03 2020 at 20:23)</a>:</h4>
<blockquote>
<p>A good number of such theorems appear to be simple REFL forms <code>t |- t</code> but that's not always true.</p>
</blockquote>
<p>Thanks a lot for the insight. BTW, we have part timer looking into adding the capability of applying REFLs or just enhancing the theorem database by equations in the other direction. We try to figure out the best way to go about it.</p>

<a name="187299905"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187299905" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187299905">Stanislas Polu (Feb 03 2020 at 20:25)</a>:</h4>
<blockquote>
<p>Another place that these theorems can come from is the assumption list in the goal. I believe around 45% of the theorem arguments in the human training steps come directly from the assumption list in the current goal. These can come from either being explicitly passed as tactic arguments, or added in bulk via an ASM_* tactic.</p>
</blockquote>
<p>I will verify how many land in that category, but probably less than 45% given the above?</p>

<a name="187300257"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187300257" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187300257">Stanislas Polu (Feb 03 2020 at 20:28)</a>:</h4>
<blockquote>
<p>Thanks a lot for the insight. BTW, we have part timer looking into adding the capability of applying REFLs or just enhancing the theorem database by equations in the other direction. We try to figure out the best way to go about it.</p>
</blockquote>
<p>The simplest cases (eg REFL) can easily be handled outside of the container; obviously with the associated decrease in trust in the proofs generated.</p>

<a name="187303840"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187303840" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187303840">Stanislas Polu (Feb 03 2020 at 21:04)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> out of curiosity do you have an example hol light theorem whose code picks an assumption argument without the use of an ASM_* tactic?</p>


{% endraw %}

{% include archive_update.html %}