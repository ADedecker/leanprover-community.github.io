---
layout: archive
title: Lean Prover Zulip Chat Archive
permalink: archive/113488general/39723CellPhoneMathematics.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/113488general/index.html">general</a>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/113488general/39723CellPhoneMathematics.html">Cell Phone Mathematics</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com">

{% raw %}
<a name="184859494"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Cell%20Phone%20Mathematics/near/184859494" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/39723CellPhoneMathematics.html#184859494">Tim Daly (Jan 05 2020 at 18:36)</a>:</h4>
<p>Can you build a cell phone from scratch? Do you understand how?</p>
<p>I've spent most of my career, such as it is, in areas that were once considered AI (vision, robotics, planning, expert systems, computer algebra, etc.). I'm a bit concerned about the impact a machine learning approach to theorem proving.</p>
<p>I am currently "fuzz testing" Axiom. That is, I have a program that randomly generates expressions which I can integrate to test the integration algorithm.</p>
<p>Note that the fuzz tester does not know anything except that expressions are trees and nodes in the trees have one, two, or many operands. Some of the generated expressions are not valid since they end up doing things like division by zero. That's not a problem as Axiom will discover that and reject that expression.</p>
<p>Note, however, that we are not remembering nor building on these random expressions.</p>
<p>Imagine that some bright-spot constructs a Neural Net AI that can prove theorems. And imagine a fuzz-tester that generates random theorems that the AI tries to prove. Sometimes it succeeds. The fuzzed theorem is correct but has no 'intrinsic meaning', just a 5000 step proof.</p>
<p>A proven theorem has value and should be remembered. It should be added to the list of proven theorems.</p>
<p>Now you arrive with your hand-generated theorem for your theory. You submit it to the AI and it generates a proof. The proof relies on a pile of prior fuzz-generated proven theorems.</p>
<p>Eventually you reach a state where everyone believes your theorem is true (since there is a proof) but no one, including you, has any clue how to prove it without the machine, or what the proof even means. </p>
<p>In other words, "It just works"... or, as I call it, Cell Phone Mathematics.</p>
<p>This used to be the stuff of science fiction. Is there some kind of mathematical "summary" theory that can be derived from a sequence of steps? Do we need an algorithm to create meta-tactics? Or is "understanding" going to be lost on the sea of random theorems?</p>

<a name="184865377"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Cell%20Phone%20Mathematics/near/184865377" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/39723CellPhoneMathematics.html#184865377">Jason Rute (Jan 05 2020 at 21:17)</a>:</h4>
<p>I think this is a common concern I've heard about computer generated proofs, namely that there will be incomprehensible proofs of interesting theorems.  We will know it is true, but not why.  However, I imagine that the advancement of computer proving (using neural networks or any other means) will be slow enough that the mathematics community will have time to adapt.  I think we are already starting to face similar issues.  The four color theorem reduces to a huge case analysis.  The classification of finite simple groups is too big for any one person to wrap their head around.  Sometimes some mathematician comes up with a lemma whose proof has no motivation.   Other times a mathematician brings in knowledge from a very different area of mathematics to prove something (leaving the mathematicians who normally work in that area a bit angry that they have to learn a whole new field of math to keep up).</p>

<a name="184865380"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Cell%20Phone%20Mathematics/near/184865380" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/39723CellPhoneMathematics.html#184865380">Jason Rute (Jan 05 2020 at 21:17)</a>:</h4>
<p>I think one possible solution to the "incomprehensible proof" problem will be that we can use the same AI tools to better understand what is going on.  We can ask the AI if certain facts are true (like an oracle) and then get a better big picture idea of what is happening.  Alternately we can look at the AI proof at different levels of granularity and try to separate out the ugly lemmas (and them try to replace that part of the proof with something more beautiful).  I think for a long time humans will have the upper hand on theory building and understanding.  I think of AI more as a new tool, like the telescope was to astronomers or the microscope to biologists.  I know combinatorists who plug in a conjecture into a computer to test the first billion numbers or so.  That way they know they aren't wasting their time.  I imagine that AI could form a similar purpose.</p>


{% endraw %}

{% include archive_update.html %}