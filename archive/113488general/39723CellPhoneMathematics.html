---
layout: archive
title: Lean Prover Zulip Chat Archive
permalink: archive/113488general/39723CellPhoneMathematics.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/113488general/index.html">general</a>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/113488general/39723CellPhoneMathematics.html">Cell Phone Mathematics</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com">

{% raw %}
<a name="184859494"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Cell%20Phone%20Mathematics/near/184859494" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/39723CellPhoneMathematics.html#184859494">Tim Daly (Jan 05 2020 at 18:36)</a>:</h4>
<p>Can you build a cell phone from scratch? Do you understand how?</p>
<p>I've spent most of my career, such as it is, in areas that were once considered AI (vision, robotics, planning, expert systems, computer algebra, etc.). I'm a bit concerned about the impact a machine learning approach to theorem proving.</p>
<p>I am currently "fuzz testing" Axiom. That is, I have a program that randomly generates expressions which I can integrate to test the integration algorithm.</p>
<p>Note that the fuzz tester does not know anything except that expressions are trees and nodes in the trees have one, two, or many operands. Some of the generated expressions are not valid since they end up doing things like division by zero. That's not a problem as Axiom will discover that and reject that expression.</p>
<p>Note, however, that we are not remembering nor building on these random expressions.</p>
<p>Imagine that some bright-spot constructs a Neural Net AI that can prove theorems. And imagine a fuzz-tester that generates random theorems that the AI tries to prove. Sometimes it succeeds. The fuzzed theorem is correct but has no 'intrinsic meaning', just a 5000 step proof.</p>
<p>A proven theorem has value and should be remembered. It should be added to the list of proven theorems.</p>
<p>Now you arrive with your hand-generated theorem for your theory. You submit it to the AI and it generates a proof. The proof relies on a pile of prior fuzz-generated proven theorems.</p>
<p>Eventually you reach a state where everyone believes your theorem is true (since there is a proof) but no one, including you, has any clue how to prove it without the machine, or what the proof even means. </p>
<p>In other words, "It just works"... or, as I call it, Cell Phone Mathematics.</p>
<p>This used to be the stuff of science fiction. Is there some kind of mathematical "summary" theory that can be derived from a sequence of steps? Do we need an algorithm to create meta-tactics? Or is "understanding" going to be lost on the sea of random theorems?</p>


{% endraw %}

{% include archive_update.html %}