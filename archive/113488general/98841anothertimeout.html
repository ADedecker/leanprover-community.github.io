---
layout: page
title: Lean Prover Zulip Chat Archive 
permalink: archive/113488general/98841anothertimeout.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/113488general/index.html">general</a>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/113488general/98841anothertimeout.html">another timeout</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com">
{% raw %}
<a name="165472346"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/another%20timeout/near/165472346" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/98841anothertimeout.html#165472346">Kevin Buzzard (May 12 2019 at 16:58)</a>:</h4>
<p>The perfectoid project currently compiles fine, according to Travis, but if I try it in VS Code I get deterministic timeouts! I have traced the issue back to VS Code feeding <code>-T100000</code> to Lean (maximum number of memory allocations per task), but Travis not doing this. </p>
<p>If I have code which is timing out with <code>-T100000</code> does this indicate that something is wrong with the code? Before, we had timeout issues which were fixed by making arbitrary universe changes. Maybe I'll try this now, but in general I am not sure what this means. I've seen my code give typeclass inference errors which could be fixed by changing the max depth, but this is the first time I've seen a timeout issue which could be fixed by changing the parameters.</p>


{% endraw %}
